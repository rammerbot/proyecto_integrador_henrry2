
<div>
    <h1>Proyecto Integrador 2 de Henry: Implementación de un MVP de Big Data en Hadoop con Docker(Pendiente por culminar - avance realizado hasta Mongo y Neo4j- falta cargar resultados)</h1>
    <div>
        <h2>¡Bienvenidos a la Revolución de Big Data!</h2>
    </div>
    <div>
        <h2>Objetivo del Proyecto</h2>
        <p><strong>Crear un MVP (Producto Viable Mínimo) de un entorno de Big Data usando Hadoop.</strong></p>
        <ul>
            <li><strong>Migración de datos:</strong> Cargar archivos CSV previamente utilizados en un datawarehouse en MySQL hacia Hadoop.</li>
            <li><strong>Demostración:</strong> Mostrar las ventajas y capacidades de la tecnología Big Data al sector de infraestructura.</li>
        </ul>
    </div>
    <div>
        <h2>Desafíos y Soluciones</h2>
        <h3>Desafío: Presupuesto Limitado</h3>
        <p><strong>Restricción:</strong> No se asignó presupuesto para utilizar proveedores de servicios en la nube (Azure, AWS, Google).</p>
        <h3>Solución: Uso de Docker</h3>
        <p><strong>Implementación:</strong> Construir el entorno Big Data utilizando contenedores Docker.</p>
        <p><strong>Ventaja:</strong> Proveer una demostración efectiva y económica sin costos adicionales.</p>
    </div>
    <div>
        <h2>¿Por Qué Hadoop?</h2>
        <ul>
            <li><strong>Escalabilidad:</strong> Maneja grandes volúmenes de datos de manera eficiente.</li>
            <li><strong>Flexibilidad:</strong> Compatible con distintos tipos de datos (estructurados y no estructurados).</li>
            <li><strong>Rendimiento:</strong> Procesamiento paralelo de datos, mejorando la velocidad y eficiencia.</li>
        </ul>
    </div>
    <div>
        <h2>Proceso de Implementación</h2>
        <ol>
            <li><strong>Preparación del Entorno Docker:</strong>
                <ul>
                    <li>Configuración de contenedores Docker para simular un cluster Hadoop.</li>
                    <li>Instalación de componentes esenciales de Hadoop (HDFS, MapReduce, YARN).</li>
                </ul>
            </li>
            <li><strong>Migración de Datos:</strong>
                <ul>
                    <li>Conversión y carga de archivos CSV desde MySQL a Hadoop.</li>
                    <li>Validación de la integridad y calidad de los datos cargados.</li>
                </ul>
            </li>
            <li><strong>Desarrollo del MVP:</strong>
                <ul>
                    <li>Configuración de workflows de procesamiento de datos.</li>
                    <li>Implementación de tareas de análisis y procesamiento en Hadoop.</li>
                </ul>
            </li>
            <li><strong>Demo al Sector de Infraestructura:</strong>
                <ul>
                    <li>Presentación de la arquitectura y el flujo de datos.</li>
                    <li>Ejemplos prácticos de procesamiento y análisis de Big Data.</li>
                    <li>Comparación de rendimiento y eficiencia frente al sistema actual.</li>
                </ul>
            </li>
        </ol>
    </div>
    <div>
        <h2>Beneficios</h2>
        <ul>
            <li><strong>Optimización de Recursos:</strong> Reducción de costos operativos mediante el uso de tecnologías open-source y Docker.</li>
            <li><strong>Mejora en Toma de Decisiones:</strong> Acceso a análisis más profundos y rápidos de grandes volúmenes de datos.</li>
            <li><strong>Preparación para el Futuro:</strong> Fundamentos sólidos para futuras expansiones y proyectos de Big Data.</li>
        </ul>
    </div>
</div>
